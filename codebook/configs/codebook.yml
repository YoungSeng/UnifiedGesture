
VQVAE:
    #Codebook Configs
    levels: 1
    downs_t: [1,]       # 3 -> 1
    strides_t : [2,]        # 2 -> 3
    emb_width : 512
    l_bins : 512
    l_mu : 0.99
    commit : 0.02
    hvqvae_multipliers : [1,]
    width: 512
    depth: 3
    m_conv : 1.0
    dilation_growth_rate : 3    # 3->1
    sample_length: 30
    use_bottleneck: True
    joint_channel: 16
    vel: 1      # 1 -> 0
    acc: 1      # 1 -> 0
    vqvae_reverse_decoder_dilation: True

VQVAE_2:
    #Codebook Configs
    levels: 1
    downs_t: [1,]       # 3 -> 1
    strides_t : [2,]        # 2 -> 3
    emb_width : 2048
    l_bins : 2048
    l_mu : 0.99
    commit : 0.02
    hvqvae_multipliers : [1,]
    width: 2048
    depth: 3
    m_conv : 1.0
    dilation_growth_rate : 3    # 3->1
    sample_length: 30
    use_bottleneck: True
    joint_channel: 16
    vel: 1      # 1 -> 0
    acc: 1      # 1 -> 0
    vqvae_reverse_decoder_dilation: True

# latent space
train_data_path: "../retargeting/datasets/Trinity_ZEGGS/bvh2upper_lower_root/lmdb_latent_vel/lmdb_train"
val_data_path: "../retargeting/datasets/Trinity_ZEGGS/bvh2upper_lower_root/lmdb_latent_vel/lmdb_test"

n_poses: 30     # 30 -> 40 -> 240
n_codes: 30
motion_resampling_framerate: 7.5     # 20 -> 60
subdivision_stride: 3      # 10 -> 30
batch_size: 128
loader_workers: 2
epochs: 600     # 500 -> 10
save_per_epochs: 60     # 20 -> 1
model_save_path: "./result/my_codebook"
name: "codebook"

betas: [0.5, 0.999]
milestones: [100, 200]
gamma: 0.1


