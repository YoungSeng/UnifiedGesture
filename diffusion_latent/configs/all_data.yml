VQVAE:
    #Codebook Configs
    levels: 1
    downs_t: [1,]       # 3 -> 1
    strides_t : [2,]        # 2 -> 3
    emb_width : 512
    l_bins : 512
    l_mu : 0.99
    commit : 0.02
    hvqvae_multipliers : [1,]
    width: 512
    depth: 3
    m_conv : 1.0
    dilation_growth_rate : 3    # 3->1
    sample_length: 30
    use_bottleneck: True
    joint_channel: 16
    vel: 1      # 1 -> 0
    acc: 1      # 1 -> 0
    vqvae_reverse_decoder_dilation: True

train_data_path: "../dataset/all_lmdb_aux/lmdb_train/"
val_data_path: "../dataset/all_lmdb_aux/lmdb_test/"

n_poses: 36   # 36
n_seed: 6   # 4
motion_resampling_framerate: 7.5
subdivision_stride: 3
batch_size: 256
loader_workers: 0
epochs: 500
save_per_epochs: 50
model_save_path: "./result/20230423/"
name: "DiffuseStyleGesture"
log_interval: 500
weight_decay: 0.0
lr_anneal_steps: 0
save_dir: "./result/inference/my_diffusion"
audio_feat: "wavlm"     # wav encoder; mfcc; wavlm

lr: 0.00003     # 0.00003 ->
betas: [0.5, 0.999]
milestones: [100, 200]
gamma: 0.1

collect:
    eps_list: [0.0, 0.25, 0.5, 0.75, 1.]
    offline_data_path: ./data/generated_noisy_data